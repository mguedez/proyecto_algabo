{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf154be",
   "metadata": {},
   "source": [
    "# Optimización de hiperparámetros con Algoritmos genéticos y Branch & Bound\n",
    "\n",
    "**Dataset:** California Housing\n",
    "\n",
    "**Autores:** Manuela Guedez Leivas y Lucía Olivera Freire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b66a13",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "Este notebook contiene una implementación reproducible que compara dos estrategias para buscar hiperparámetros de un `RandomForestRegressor` sobre el dataset *California Housing*:\n",
    "\n",
    "- **Algoritmo Genético (GA)** con elitismo, mutación y early stopping (patience).\n",
    "- **Búsqueda Exhaustiva / Branch & Bound (B&B)** (aquí implementada como búsqueda sistemática con memoización; dado que no es naturalmente apto para el uso de programación dinámica, la búsqueda explora el espacio completo pero registra el progreso para comparar).\n",
    "\n",
    "El objetivo es mostrar cómo evolucionan el *fitness* (aquí definido como `-RMSE` para poder maximizar) a lo largo de las evaluaciones de cada método y comparar resultados finales. Se incluyen celdas para instalar dependencias, preprocesamiento, funciones con documentación y visualizaciones comparativas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df559e67",
   "metadata": {},
   "source": [
    "\n",
    "## Requisitos e instalación\n",
    "\n",
    "Ejecuta esta celda para instalar las librerías necesarias (si usas un entorno ya configurado, puedes omitirla):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2acb9d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./venv/lib/python3.13/site-packages (25.1.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.1.1\n",
      "    Uninstalling pip-25.1.1:\n",
      "      Successfully uninstalled pip-25.1.1\n",
      "Successfully installed pip-25.3\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.13/site-packages (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.13/site-packages (1.7.2)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (113 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-12.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached matplotlib-3.10.7-cp313-cp313-macosx_11_0_arm64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl (274 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.0-cp313-cp313-macosx_10_13_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl (64 kB)\n",
      "Using cached pillow-12.0.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [matplotlib]7\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.0 kiwisolver-1.4.9 matplotlib-3.10.7 pillow-12.0.0 pyparsing-3.2.5\n"
     ]
    }
   ],
   "source": [
    "# ejecuta en una celda de terminal o prefijo ! en una celda de Jupyter\n",
    "!pip3 install --upgrade pip\n",
    "!pip3 install pandas numpy scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b1d22",
   "metadata": {},
   "source": [
    "## 0. Imports y configuración global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033ba177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import itertools\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Reproducibilidad\n",
    "RANDOM_STATE = 127\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16403e",
   "metadata": {},
   "source": [
    "## 1. Carga y preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a12b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga (asegúrate de tener 'housing.csv' en la misma carpeta o ajusta la ruta)\n",
    "housing = pd.read_csv('housing.csv').dropna()\n",
    "\n",
    "X = housing.drop(columns=['median_house_value'])\n",
    "y = housing['median_house_value']\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "# Batch del 10% para evaluación rápida dentro del GA y B&B\n",
    "X_train_full, X_batch, y_train_full, y_batch = train_test_split(X_train, y_train, test_size=0.1, random_state=RANDOM_STATE)\n",
    "\n",
    "num_features = [\n",
    "    'longitude', 'latitude', 'housing_median_age',\n",
    "    'total_rooms', 'total_bedrooms', 'population',\n",
    "    'households', 'median_income'\n",
    "]\n",
    "cat_features = ['ocean_proximity']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdee3d11",
   "metadata": {},
   "source": [
    "## 2. Función de evaluación (fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed8b1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_rmse(params, Xb, yb):\n",
    "    \"\"\"\n",
    "    Evaluación del modelo con RMSE negativo (para que un mayor fitness sea mejor).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : dict\n",
    "        Hiperparámetros para RandomForestRegressor (ej: {'n_estimators':100, ...}).\n",
    "    Xb : pd.DataFrame\n",
    "        Features del conjunto de evaluación.\n",
    "    yb : pd.Series / array\n",
    "        Target del conjunto de evaluación.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Fitness = -RMSE (valor negativo, se busca maximizar).\n",
    "    \"\"\"\n",
    "    model = Pipeline([\n",
    "        ('pre', preprocessor),\n",
    "        ('rf', RandomForestRegressor(**params, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    model.fit(Xb, yb)\n",
    "    pred = model.predict(Xb)\n",
    "    rmse = np.sqrt(mean_squared_error(yb, pred))\n",
    "    return -rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dceefe",
   "metadata": {},
   "source": [
    "## 3. Espacio de búsqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1a48539",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300],\n",
    "    'max_depth': [4, 6, 8, 10, 12, 14, None],\n",
    "    'min_samples_split': [2, 4, 6, 8],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2a922",
   "metadata": {},
   "source": [
    "## 4. Operadores genéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ae3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_params():\n",
    "    \"\"\"\n",
    "    Genera un individuo aleatorio del espacio de hiperparámetros.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Hiperparámetros con valores elegidos al azar.\n",
    "    \"\"\"\n",
    "    return {k: random.choice(v) for k, v in param_space.items()}\n",
    "\n",
    "\n",
    "def mutate(params, mutation_rate=0.4):\n",
    "    \"\"\"\n",
    "    Aplica mutación a un individuo.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : dict\n",
    "        Individuo a mutar.\n",
    "    mutation_rate : float\n",
    "        Probabilidad de que ocurra una mutación.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Nuevo individuo (posiblemente mutado).\n",
    "    \"\"\"\n",
    "    new_params = params.copy()\n",
    "    if random.random() < mutation_rate:\n",
    "        key = random.choice(list(param_space.keys()))\n",
    "        new_params[key] = random.choice(param_space[key])\n",
    "    return new_params\n",
    "\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    \"\"\"\n",
    "    Cruza dos padres y devuelve un hijo combinando aleatoriamente cada clave.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p1, p2 : dict\n",
    "        Padres.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Hijo resultante.\n",
    "    \"\"\"\n",
    "    return {k: random.choice([p1[k], p2[k]]) for k in param_space.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6afd3e",
   "metadata": {},
   "source": [
    "## 5. Algoritmo Genético (con historial de fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "641a4552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_optimize(\n",
    "    generations=100,\n",
    "    population_size=40,\n",
    "    elitism=0.1,\n",
    "    patience=10,\n",
    "    min_improvement=0.01,\n",
    "    mutation_rate=0.4\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejecuta un GA sencillo que devuelve el mejor individuo y la historia del mejor fitness por generación.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    generations : int\n",
    "        Número máximo de generaciones.\n",
    "    population_size : int\n",
    "        Tamaño de la población.\n",
    "    elitism : float\n",
    "        Fracción de la población que se conserva sin cambios.\n",
    "    patience : int\n",
    "        Número de generaciones sin mejora para detener temprano.\n",
    "    min_improvement : float\n",
    "        Mejora relativa mínima requerida para resetear patience (ej: 0.01 = 1%).\n",
    "    mutation_rate : float\n",
    "        Probabilidad de mutación.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (best_score, best_params, history)\n",
    "        - best_score : float, mejor fitness encontrado\n",
    "        - best_params : dict, hiperparámetros del mejor individuo\n",
    "        - history : list[float], mejor fitness por generación\n",
    "    \"\"\"\n",
    "    population = [random_params() for _ in range(population_size)]\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    generations_without_improvement = 0\n",
    "    history = []\n",
    "\n",
    "    for gen in range(generations):\n",
    "        scores = [(fitness_rmse(p, X_batch, y_batch), p) for p in population]\n",
    "        scores.sort(reverse=True, key=lambda x: x[0])\n",
    "        gen_best_score, gen_best_params = scores[0]\n",
    "        history.append(gen_best_score)\n",
    "        print(f\"[GA] Gen {gen+1} | Mejor -RMSE: {gen_best_score:.4f}\")\n",
    "\n",
    "        if best_score == -np.inf:\n",
    "            best_score = gen_best_score\n",
    "            best_params = gen_best_params\n",
    "        else:\n",
    "            improvement = (gen_best_score - best_score) / abs(best_score) if best_score != 0 else np.inf\n",
    "            if improvement >= min_improvement:\n",
    "                best_score = gen_best_score\n",
    "                best_params = gen_best_params\n",
    "                generations_without_improvement = 0\n",
    "            else:\n",
    "                generations_without_improvement += 1\n",
    "\n",
    "            if generations_without_improvement >= patience:\n",
    "                print(f\"Early stopping en GA: sin mejora > {min_improvement*100:.1f}% en {patience} generaciones.\")\n",
    "                break\n",
    "\n",
    "        # Elitismo y reproducción\n",
    "        n_elite = max(1, int(population_size * elitism))\n",
    "        next_gen = [p for _, p in scores[:n_elite]]\n",
    "        while len(next_gen) < population_size:\n",
    "            p1, p2 = random.sample(population, 2)\n",
    "            child = mutate(crossover(p1, p2), mutation_rate=mutation_rate)\n",
    "            next_gen.append(child)\n",
    "        population = next_gen\n",
    "\n",
    "    return best_score, best_params, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896d6dd",
   "metadata": {},
   "source": [
    "## 6. Branch & Bound / Búsqueda Exhaustiva con registro de progreso\n",
    "\n",
    "> Nota: el enfoque de B&B tal como se comentó en el informe no se adapta bien al tuning porque no existe una estructura de subproblemas combinables. Para comparar en forma práctica, aquí evaluamos *exhaustivamente* todas las combinaciones, pero mantenemos un historial del mejor fitness a medida que avanzamos. Esto emula la idea de \"mejor solución encontrada hasta ahora\" durante una búsqueda completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b586b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def exhaustive_search_with_progress(param_space):\n",
    "    \"\"\"\n",
    "    Evalúa exhaustivamente todas las combinaciones del espacio de parámetros y devuelve\n",
    "    el mejor encontrado y la historia del mejor fitness tras cada evaluación.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    param_space : dict\n",
    "        Diccionario con listas de valores por cada hiperparámetro.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (best_params, best_score, history)\n",
    "        - best_params : dict, mejor configuración encontrada\n",
    "        - best_score : float, mejor fitness (mayor)\n",
    "        - history : list[float], mejor fitness después de cada evaluación\n",
    "    \"\"\"\n",
    "    keys = list(param_space.keys())\n",
    "    all_values = list(product(*(param_space[k] for k in keys)))\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    history = []\n",
    "\n",
    "    for i, vals in enumerate(all_values, 1):\n",
    "        candidate = dict(zip(keys, vals))\n",
    "        score = fitness_rmse(candidate, X_batch, y_batch)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = candidate\n",
    "        history.append(best_score)\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[B&B] Evaluadas {i}/{len(all_values)} configuraciones | Mejor -RMSE: {best_score:.4f}\")\n",
    "\n",
    "    return best_params, best_score, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e007c4",
   "metadata": {},
   "source": [
    "## 7. Ejecución de ambos métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6ec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OPTIMIZACIÓN GENÉTICA ===\n",
      "[GA] Gen 1 | Mejor -RMSE: -27455.2682\n",
      "[GA] Gen 2 | Mejor -RMSE: -26251.4349\n",
      "[GA] Gen 3 | Mejor -RMSE: -26251.4349\n"
     ]
    }
   ],
   "source": [
    "# Ajustar parámetros si se quiere ejecutar menos generaciones durante pruebas\n",
    "GA_GENERATIONS = 60\n",
    "GA_POPSIZE = 30\n",
    "\n",
    "print('\\n=== OPTIMIZACIÓN GENÉTICA ===')\n",
    "best_ga_score, best_ga_params, ga_history = genetic_optimize(\n",
    "    generations=GA_GENERATIONS,\n",
    "    population_size=GA_POPSIZE,\n",
    "    elitism=0.1,\n",
    "    patience=15,\n",
    "    min_improvement=0.005,  # 0.5% para pruebas\n",
    "    mutation_rate=0.4\n",
    ")\n",
    "\n",
    "print('\\n=== BÚSQUEDA EXHAUSTIVA (B&B emulado) ===')\n",
    "best_bb_params, best_bb_score, bb_history = exhaustive_search_with_progress(param_space)\n",
    "\n",
    "print('\\nRESULTADOS FINALES')\n",
    "print('------------------')\n",
    "print(f\"Mejor fitness (GA): {-best_ga_score:.4f} RMSE\")\n",
    "print(f\"Hiperparámetros (GA): {best_ga_params}\\n\")\n",
    "print(f\"Mejor fitness (B&B): {-best_bb_score:.4f} RMSE\")\n",
    "print(f\"Hiperparámetros (B&B): {best_bb_params}\\n\")\n",
    "\n",
    "# Entrenar modelo final con la mejor configuración GA (o B&B si prefieres)\n",
    "final_model = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('rf', RandomForestRegressor(**best_ga_params, random_state=RANDOM_STATE))\n",
    "])\n",
    "final_model.fit(X_train, y_train)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, final_model.predict(X_test)))\n",
    "print(f\"RMS E en test (modelo final - GA): {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f537a",
   "metadata": {},
   "source": [
    "## 8. Visualizaciones comparativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Evolución del mejor fitness\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(ga_history)+1), [-v for v in ga_history], label='GA (-RMSE -> RMSE)'),\n",
    "plt.plot(range(1, len(bb_history)+1), [-v for v in bb_history], label='B&B (exhaustiva)')\n",
    "plt.xlabel('Evaluación (index)')\n",
    "plt.ylabel('RMSE (mejor hasta el momento)')\n",
    "plt.title('Evolución del mejor RMSE (GA vs B&B)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 2) Comparación final (barra)\n",
    "final_rmse_ga = -best_ga_score\n",
    "final_rmse_bb = -best_bb_score\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(['GA', 'B&B'], [final_rmse_ga, final_rmse_bb])\n",
    "plt.ylabel('RMSE (menor es mejor)')\n",
    "plt.title('Comparación final de RMSE entre métodos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55860f6",
   "metadata": {},
   "source": [
    "## 9. Comentarios finales y buenas prácticas\n",
    "\n",
    "- Cada función tiene docstrings que describen parámetros, retornos y comportamiento (resumido).\n",
    "- Para notebooks reproducibles: fijar seeds, documentar celdas y reducir el dataset (batch) para pruebas rápidas.\n",
    "- Atención: la búsqueda exhaustiva puede ser costosa. En este espacio de ejemplo hay 840 combinaciones (6*7*4*5) — dependiendo de cuánto pese el entrenamiento, la búsqueda completa puede tardar.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
